{
  "metadata": {
    "name": "data-cleaning-and-profiling",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Data Cleaning"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Reading author data into a Dataframe"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val datafilePath \u003d \"bdad-proj/goodreads_book_authors.json\"\nval authorsDf \u003d spark.read.json(datafilePath)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(authorsDf)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "authorsDf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val origEntryCount \u003d authorsDf.count()\nval numAttributes \u003d authorsDf.columns.size"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Removing entries with null values\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nonNullEntriesDF \u003d authorsDf.na.drop(Seq(\"author_id\"))\nval newEntryCount \u003d nonNullEntriesDF.count()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Reading books data for augmentation"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val booksDatafilePath \u003d \"bdad-proj/goodreads_books.json\"\nval booksDF \u003d spark.read.json(booksDatafilePath)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "booksDF.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Working with publication years"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val booksWithAuthors \u003d booksDF.select($\"book_id\", $\"authors\", $\"publication_year\")\nz.show(booksWithAuthors)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val normalizedBwA \u003d booksWithAuthors.select($\"book_id\", $\"publication_year\", explode($\"authors\").alias(\"author\"))\nz.show(normalizedBwA)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Converting years into int and using explode to normalize data"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val authorBookCount \u003d normalizedBwA.select(\"book_id\", \"publication_year\", \"author.author_id\", \"author.role\").filter($\"role\" \u003d\u003d\u003d \"\")\n    .groupBy(col(\"author_id\").alias(\"auth_id\")).count()\n\nnormalizedBwA.printSchema()\n\nval castDF \u003d normalizedBwA.select(normalizedBwA.columns.map {\n    case column@\"publication_year\" \u003d\u003e\n      col(column).cast(\"int\").as(column)\n    case column \u003d\u003e\n      col(column)\n  }: _*)\n  \ncastDF.printSchema()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Selecting the first and last publication years"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val _firstYear \u003d castDF.select(\"publication_year\", \"author.author_id\", \"author.role\").filter($\"role\" \u003d\u003d\u003d \"\")\n    .groupBy(col(\"author_id\").alias(\"auth_id\")).min(\"publication_year\")\n\nval firstYear \u003d _firstYear.filter(_firstYear(\"min(publication_year)\") \u003e 1000 \u0026\u0026 _firstYear(\"min(publication_year)\") \u003c 2023)\n    \nval _lastYear \u003d castDF.select(\"publication_year\", \"author.author_id\", \"author.role\").filter($\"role\" \u003d\u003d\u003d \"\")\n    .groupBy(col(\"author_id\").alias(\"auth_id_2\")).max(\"publication_year\")\n    \nval lastYear \u003d _lastYear.filter(_lastYear(\"max(publication_year)\") \u003e 1000 \u0026\u0026 _lastYear(\"max(publication_year)\") \u003c 2023)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val yearsActive \u003d firstYear.join(lastYear, firstYear(\"auth_id\") \u003d\u003d\u003d lastYear(\"auth_id_2\"), \"fullouter\")\nyearsActive.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val authorWYearsDF \u003d nonNullEntriesDF.join(yearsActive, nonNullEntriesDF(\"author_id\") \u003d\u003d\u003d yearsActive(\"auth_id\"), \"leftouter\").drop(\"auth_id\", \"auth_id_2\")\n\nauthorWYearsDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val authorWYearsRenamedDF \u003d authorWYearsDF\n    .withColumnRenamed(\"author_id\", \"auth\")\n    .withColumnRenamed(\"min(publication_year)\", \"first_published_in\")\n    .withColumnRenamed(\"max(publication_year)\", \"last_published_in\")\n    .select(\"auth\", \"first_published_in\", \"last_published_in\")\nz.show(authorWYearsRenamedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val augmentedAuthorDF \u003d nonNullEntriesDF.join(authorBookCount, nonNullEntriesDF(\"author_id\") \u003d\u003d\u003d authorBookCount(\"auth_id\"), \"leftouter\")\n    .drop(\"auth_id\").na.fill(0,Array(\"count\")).withColumnRenamed(\"count\", \"books_count\")\nz.show(augmentedAuthorDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val finalDF \u003d augmentedAuthorDF.join(authorWYearsRenamedDF, augmentedAuthorDF(\"author_id\") \u003d\u003d\u003d authorWYearsRenamedDF(\"auth\"), \"leftouter\").drop(\"auth\")\n\nz.show(finalDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val authorsOutputDF \u003d finalDF\nauthorsOutputDF.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "authorsOutputDF.write.parquet(\"bdad-proj/data-prof-clean/goodreads_authors_2.parquet\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Some Data Profiling"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Performing some aggregation statistics"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val starDistributions \u003d authorsOutputDF.withColumn(\"avg_rating\", round(col(\"average_rating\"), 0)).groupBy(\"avg_rating\").count()\nz.show(starDistributions)"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val bookCountDistributions \u003d authorsOutputDF.groupBy(\"books_count\").count()\nz.show(bookCountDistributions)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val totalNumberOfAuthors \u003d authorsOutputDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val startYear \u003d authorsOutputDF.na.drop(Seq(\"first_published_in\")).groupBy(\"first_published_in\").count()\nz.show(startYear)"
    }
  ]
}